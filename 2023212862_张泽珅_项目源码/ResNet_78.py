import os
import time
import copy
import glob
import re
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import datasets, models, transforms
from torch.cuda.amp import autocast, GradScaler  # æ··åˆç²¾åº¦è®­ç»ƒ
import pandas as pd
from PIL import Image
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix

# ==========================================
# 1. é…ç½®å‚æ•° (Configuration)
# ==========================================
class Config:
    # è·¯å¾„é…ç½® (æ ¹æ®ä½ çš„ tree ç»“æ„)
    DATA_ROOT = r"/root/autodl-tmp/Classify/data"
    TRAIN_DIR = os.path.join(DATA_ROOT, "basic_data")
    PRED_DIR = os.path.join(DATA_ROOT, "pred_data")
    OUTPUT_FILE = "pred_result.csv"
    MODEL_SAVE_PATH = "models/best_model.pth"
    
    # ç¡¬ä»¶å‚æ•°
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    NUM_WORKERS = 8 # Ultra 9 æ ¸å¿ƒå¤šï¼Œå¯ä»¥é€‚å½“è°ƒé«˜ï¼ŒåŠ é€ŸIO
    PIN_MEMORY = True
    
    # è®­ç»ƒè¶…å‚æ•°
    IMG_SIZE = 150
    BATCH_SIZE = 128  # 32GB æ˜¾å­˜å¯ä»¥å¼€å¾—å¾ˆå¤§ï¼Œ128-256å‡å¯
    EPOCHS = 15       # è¿ç§»å­¦ä¹ é€šå¸¸ä¸éœ€è¦å¤ªä¹…
    LEARNING_RATE = 1e-4
    NUM_CLASSES = 6
    
    # æ ‡ç­¾æ˜ å°„ (æ ¹æ®é¢˜ç›®æè¿°)
    CLASS_NAMES = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']
    # é¢˜ç›®ç»™å®šçš„æ ‡ç­¾æ˜ å°„: buildings0, forest1, ...
    LABEL_MAP = {name: idx for idx, name in enumerate(CLASS_NAMES)}

print(f"ğŸš€ Running on device: {Config.DEVICE}")
if torch.cuda.is_available():
    print(f"   GPU: {torch.cuda.get_device_name(0)}")

# ==========================================
# 2. æ•°æ®å¤„ç†ä¸å¢å¼º (Data Processing)
# ==========================================
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15), # å¢åŠ éšæœºæ—‹è½¬ï¼Œæå‡é²æ£’æ€§
        transforms.ColorJitter(brightness=0.1, contrast=0.1), # ç¨å¾®è°ƒæ•´è‰²å½©
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # ImageNet æ ‡å‡†å‡å€¼æ–¹å·®
    ]),
    'val': transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    # é¢„æµ‹é›†ä¸éœ€è¦å¢å¼ºï¼Œåªéœ€è¦å½’ä¸€åŒ–
    'pred': transforms.Compose([
        transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

# ==========================================
# 3. æ•°æ®é›†å‡†å¤‡ (Dataset Preparation)
# ==========================================

# 3.1 åŠ è½½ Basic Data å¹¶åˆ’åˆ†
full_dataset = datasets.ImageFolder(Config.TRAIN_DIR) # åŸå§‹æ•°æ®é›†
# ç¡®ä¿ ImageFolder è¯»å–çš„ç±»åˆ«é¡ºåºä¸é¢˜ç›®è¦æ±‚ä¸€è‡´
# ImageFolder é»˜è®¤æŒ‰å­—æ¯é¡ºåºæ’åº classesï¼Œæˆ‘ä»¬éœ€è¦æ ¸å¯¹ä¸€ä¸‹
print(f"æ£€æµ‹åˆ°çš„ç±»åˆ«æ˜ å°„: {full_dataset.class_to_idx}")
# å¦‚æœ ImageFolder çš„æ˜ å°„ä¸é¢˜ç›®è¦æ±‚çš„ 0-5 ä¸ä¸€è‡´ï¼Œéœ€è¦æ‰‹åŠ¨è°ƒæ•´ï¼Œä½†æ­¤å¤„æŒ‰é¦–å­—æ¯æ’åºæ°å¥½ç¬¦åˆ:
# buildings(0), forest(1), glacier(2), mountain(3), sea(4), street(5) -> ç¬¦åˆé¢˜ç›®ã€‚

# åˆ’åˆ† è®­ç»ƒé›†(80%) / éªŒè¯é›†(10%) / æµ‹è¯•é›†(10%)
train_size = int(0.8 * len(full_dataset))
val_size = int(0.1 * len(full_dataset))
test_size = len(full_dataset) - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(
    full_dataset, [train_size, val_size, test_size], 
    generator=torch.Generator().manual_seed(42) # å›ºå®šéšæœºç§å­ä»¥ä¾¿å¤ç°
)

# åº”ç”¨å¯¹åº”çš„ Transform (ç”±äº random_split åªæ˜¯å­é›†å¼•ç”¨ï¼Œéœ€è¦é‡å†™ Dataset ç±»æˆ–æ‰‹åŠ¨åº”ç”¨ï¼Œ
# è¿™é‡Œä¸ºäº†ç®€ä¾¿ï¼Œæˆ‘ä»¬åœ¨ Loader é˜¶æ®µæˆ–è€…ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ Wrapper)
class TransformSubset(Dataset):
    def __init__(self, subset, transform=None):
        self.subset = subset
        self.transform = transform
        
    def __getitem__(self, index):
        x, y = self.subset[index]
        if self.transform:
            x = self.transform(x)
        return x, y
        
    def __len__(self):
        return len(self.subset)

train_set = TransformSubset(train_dataset, data_transforms['train'])
val_set = TransformSubset(val_dataset, data_transforms['val'])
test_set = TransformSubset(test_dataset, data_transforms['val'])

train_loader = DataLoader(train_set, batch_size=Config.BATCH_SIZE, shuffle=True, 
                          num_workers=Config.NUM_WORKERS, pin_memory=Config.PIN_MEMORY)
val_loader = DataLoader(val_set, batch_size=Config.BATCH_SIZE, shuffle=False, 
                        num_workers=Config.NUM_WORKERS, pin_memory=Config.PIN_MEMORY)
test_loader = DataLoader(test_set, batch_size=Config.BATCH_SIZE, shuffle=False, 
                         num_workers=Config.NUM_WORKERS, pin_memory=Config.PIN_MEMORY)

# 3.2 è‡ªå®šä¹‰é¢„æµ‹æ•°æ®é›†ç±» (é’ˆå¯¹ 001.jpg æ ¼å¼ä¼˜åŒ–)
# ==========================================
class PredDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        all_files = glob.glob(os.path.join(root_dir, "*"))
        # è¿‡æ»¤éå›¾ç‰‡æ–‡ä»¶
        self.image_files = [f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        # æ’åºé€»è¾‘ä¼˜åŒ–ï¼š
        # å¯¹äº 001.jpg, 002.jpg è¿™ç§æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²æ’åºå³å¯ä¿è¯é¡ºåºæ­£ç¡®
        # ä½†ä¸ºäº†ç»å¯¹ç¨³å¥ï¼Œæˆ‘ä»¬ä¾ç„¶æå–æ•°å­—éƒ¨åˆ†è¿›è¡Œæ’åº
        self.image_files.sort(key=lambda x: int(re.search(r'\d+', os.path.basename(x)).group()))
        
        # æ‰“å°å‰3ä¸ªå’Œæœ€å3ä¸ªæ–‡ä»¶ï¼Œä¾›ä½ è‡ªæŸ¥é¡ºåºæ˜¯å¦æ­£ç¡®
        print(f"Dataset Log: æ£€æµ‹åˆ° {len(self.image_files)} å¼ é¢„æµ‹å›¾ç‰‡")
        if len(self.image_files) > 0:
            print(f"Dataset Log: æ’åºé¦–ä½æ–‡ä»¶: {os.path.basename(self.image_files[0])} -> ID: {int(re.search(r'\d+', os.path.basename(self.image_files[0])).group())}")
            print(f"Dataset Log: æ’åºæœ«ä½æ–‡ä»¶: {os.path.basename(self.image_files[-1])} -> ID: {int(re.search(r'\d+', os.path.basename(self.image_files[-1])).group())}")
        
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        image = Image.open(img_path).convert('RGB')
        
        # æ ¸å¿ƒé€»è¾‘ï¼šæå–æ–‡ä»¶åä¸­çš„æ•°å­—å¹¶è½¬ä¸ºæ•´æ•°
        # ä¾‹å¦‚: "001.jpg" -> re æå–å‡º "001" -> int("001") å˜æˆ 1
        # è¿™å®Œç¾é€‚é… csv ä¸­çš„ pic_num æ ¼å¼
        filename = os.path.basename(img_path)
        try:
            # æŸ¥æ‰¾æ–‡ä»¶åä¸­çš„ç¬¬ä¸€ä¸ªè¿ç»­æ•°å­—ä¸²
            pic_num_str = re.search(r'\d+', filename).group()
            pic_num = int(pic_num_str)
        except:
            # ä¸‡ä¸€æ–‡ä»¶åæ²¡æœ‰æ•°å­—ï¼ˆæå°æ¦‚ç‡ï¼‰ï¼Œå›é€€åˆ°ä½¿ç”¨ç´¢å¼•
            print(f"Warning: æ— æ³•ä»æ–‡ä»¶å {filename} æå–æ•°å­—ï¼Œä½¿ç”¨ç´¢å¼•ä»£æ›¿")
            pic_num = idx + 1 
            
        if self.transform:
            image = self.transform(image)
            
        return image, pic_num

# é‡æ–°å®ä¾‹åŒ– DataLoader
pred_dataset = PredDataset(Config.PRED_DIR, transform=data_transforms['pred'])
pred_loader = DataLoader(pred_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=Config.NUM_WORKERS)

# ==========================================
# 4. æ¨¡å‹æ„å»º (Model Setup - Transfer Learning)
# ==========================================
def build_model():
    # ä½¿ç”¨ ResNet50 é¢„è®­ç»ƒæ¨¡å‹
    #  - æŠ¥å‘Šä¸­å¯ä»¥æ’å…¥ ResNet ç»“æ„å›¾
    model = models.resnet50(pretrained=True)
    
    # å†»ç»“æ‰€æœ‰å±‚ (åªè®­ç»ƒå…¨è¿æ¥å±‚) -> ä¹Ÿå¯ä»¥é€‰æ‹©è§£å†»æœ€åå‡ å±‚ Fine-tune
    for param in model.parameters():
        param.requires_grad = False
        
    # ä¿®æ”¹å…¨è¿æ¥å±‚
    num_ftrs = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Linear(num_ftrs, 512),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(512, Config.NUM_CLASSES)
    )
    
    return model.to(Config.DEVICE)

model = build_model()
criterion = nn.CrossEntropyLoss()
# ä¼˜åŒ–å™¨åªä¼˜åŒ– fc å±‚çš„å‚æ•°
optimizer = optim.AdamW(model.fc.parameters(), lr=Config.LEARNING_RATE)
# å­¦ä¹ ç‡è°ƒåº¦å™¨
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)
# æ··åˆç²¾åº¦ Scaler
scaler = GradScaler()

# ==========================================
# 5. è®­ç»ƒä¸éªŒè¯æµç¨‹ (Training Loop)
# ==========================================
def train_model(model, train_loader, val_loader, epochs):
    best_acc = 0.0
    
    # ç¡®ä¿ models æ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs(os.path.dirname(Config.MODEL_SAVE_PATH), exist_ok=True)

    for epoch in range(epochs):
        print(f"\nEpoch {epoch+1}/{epochs}")
        print("-" * 10)
        
        # --- è®­ç»ƒé˜¶æ®µ ---
        model.train()
        running_loss = 0.0
        running_corrects = 0
        
        for inputs, labels in tqdm(train_loader, desc="Training"):
            inputs = inputs.to(Config.DEVICE)
            labels = labels.to(Config.DEVICE)
            
            optimizer.zero_grad()
            
            # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
            with autocast():
                outputs = model(inputs)
                loss = criterion(outputs, labels)
            
            # æ··åˆç²¾åº¦åå‘ä¼ æ’­
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            _, preds = torch.max(outputs, 1)
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)
            
        epoch_loss = running_loss / len(train_set)
        epoch_acc = running_corrects.double() / len(train_set)
        print(f"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")
        
        # --- éªŒè¯é˜¶æ®µ ---
        model.eval()
        val_running_corrects = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs = inputs.to(Config.DEVICE)
                labels = labels.to(Config.DEVICE)
                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                val_running_corrects += torch.sum(preds == labels.data)
        
        val_acc = val_running_corrects.double() / len(val_set)
        print(f"Val Acc: {val_acc:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), Config.MODEL_SAVE_PATH)
            print("âœ¨ Best model saved!")
            
        scheduler.step()

    print(f"\nTraining complete. Best Val Acc: {best_acc:.4f}")
    return model

# ==========================================
# 6. æ‰§è¡Œè®­ç»ƒ
# ==========================================
# å¦‚æœåªæ˜¯æµ‹è¯•ï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œï¼ŒåŠ è½½å·²ä¿å­˜çš„æ¨¡å‹
print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
model = train_model(model, train_loader, val_loader, Config.EPOCHS)

# åŠ è½½æœ€ä½³æ¨¡å‹å‚æ•°
model.load_state_dict(torch.load(Config.MODEL_SAVE_PATH))

# ==========================================
# 7. æµ‹è¯•é›†è¯„ä¼° (Evaluation on Test Set)
# ==========================================
print("\nåœ¨ç‹¬ç«‹æµ‹è¯•é›†ä¸Šè¯„ä¼°...")
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs = inputs.to(Config.DEVICE)
        labels = labels.to(Config.DEVICE)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# è¾“å‡ºåˆ†ç±»æŠ¥å‘Š (Precision, Recall, F1-Score)
print(classification_report(all_labels, all_preds, target_names=Config.CLASS_NAMES))

# ==========================================
# 8. é¢„æµ‹å¹¶ç”Ÿæˆç»“æœæ–‡ä»¶ (Prediction & Export)
# ==========================================
print(f"\næ­£åœ¨å¯¹ {len(pred_dataset)} å¼ å›¾ç‰‡è¿›è¡Œé¢„æµ‹...")
model.eval()
results = [] # å­˜å‚¨ç»“æœ [pic_num, predict_label]

with torch.no_grad():
    for inputs, pic_nums in tqdm(pred_loader, desc="Predicting"):
        inputs = inputs.to(Config.DEVICE)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        
        # å°† tensor è½¬ä¸º list
        preds = preds.cpu().numpy()
        pic_nums = pic_nums.numpy()
        
        for num, label in zip(pic_nums, preds):
            results.append({'pic_num': num, 'predict_label': label})

# åˆ›å»º DataFrame å¹¶ä¿å­˜
df = pd.DataFrame(results)

# ç¡®ä¿æŒ‰ç…§ pic_num æ’åº (å¦‚æœä¹‹å‰æ˜¯ä¹±åºçš„)
df = df.sort_values(by='pic_num')

# æ£€æŸ¥æ˜¯å¦æœ‰é™„ä»¶ä¸­è¦æ±‚çš„åˆ—å
print("é¢„è§ˆå‰5è¡Œæ•°æ®:")
print(df.head())

# ä¿å­˜ä¸º CSV (æ³¨æ„ï¼šé¢˜ç›®è™½ç„¶è¯´ .xlsx, ä½†é™„ä»¶å’Œè¾“å‡ºç¤ºä¾‹é€šå¸¸ç”¨ csv æ›´ç¨³å¦¥ï¼Œ
# å¦‚æœä¸¥æ ¼è¦æ±‚ xlsxï¼Œè¯·å°†ä¸‹é¢çš„ to_csv æ”¹ä¸º to_excelï¼Œå¹¶å®‰è£… openpyxl)
# æ ¹æ®ä½ æä¾›çš„é™„ä»¶æ˜¯ csvï¼Œè¿™é‡Œä¼˜å…ˆç”Ÿæˆ csv
output_csv_path = os.path.join(os.path.dirname(Config.DATA_ROOT), Config.OUTPUT_FILE)
df.to_csv(output_csv_path, index=False)
print(f"âœ… ç»“æœå·²ä¿å­˜è‡³: {output_csv_path}")